{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING PROJECT: MOBILE PHONE PRICE PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
       "0        188        2  ...         20       756  2549     9     7         19   \n",
       "1        136        3  ...        905      1988  2631    17     3          7   \n",
       "2        145        5  ...       1263      1716  2603    11     2          9   \n",
       "3        131        6  ...       1216      1786  2769    16     8         11   \n",
       "4        141        2  ...       1208      1212  1411     8     2         15   \n",
       "\n",
       "   three_g  touch_screen  wifi  price_range  \n",
       "0        0             0     1            1  \n",
       "1        1             1     0            2  \n",
       "2        1             1     0            2  \n",
       "3        1             0     0            2  \n",
       "4        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the attributes of our dataset:\n",
    "       \n",
    "       battery_power: Total energy a battery can store in one time measured in mAh\n",
    "       blue: Has bluetooth or not\n",
    "       clock_speed: speed at which microprocessor executes instructions\n",
    "       dual_sim: Has dual sim support or not\n",
    "       fc: Front Camera mega pixels\n",
    "       four_g: Has 4G or not\n",
    "       int_memory: Internal Memory in Gigabytes\n",
    "       m_dep: Mobile Depth in cm\n",
    "       mobile_wt: Weight of mobile phone\n",
    "       n_cores: Number of cores of processor\n",
    "       pc: Primary Camera mega pixels\n",
    "       px_height: Pixel Resolution Height\n",
    "       px_width: Pixel Resolution Width\n",
    "       ram: Random Access Memory in Megabytes\n",
    "       sc_h: Screen Height of mobile in cm\n",
    "       sc_w: Screen Width of mobile in cm\n",
    "       talk_time: longest time that a single battery charge will last when you are\n",
    "       three_g: Has 3G or not\n",
    "       touch_screen: Has touch screen or not\n",
    "       wifi: Has wifi or not\n",
    "       price_range: This is the target variable with value of 0 (low cost), 1 (medium cost), 2 (high cost) and 3 (very high cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are no null values in this data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1238.518500</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>1.522250</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>4.309500</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>32.046500</td>\n",
       "      <td>0.501750</td>\n",
       "      <td>140.249000</td>\n",
       "      <td>4.520500</td>\n",
       "      <td>...</td>\n",
       "      <td>645.108000</td>\n",
       "      <td>1251.515500</td>\n",
       "      <td>2124.213000</td>\n",
       "      <td>12.306500</td>\n",
       "      <td>5.767000</td>\n",
       "      <td>11.011000</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>439.418206</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>4.341444</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>18.145715</td>\n",
       "      <td>0.288416</td>\n",
       "      <td>35.399655</td>\n",
       "      <td>2.287837</td>\n",
       "      <td>...</td>\n",
       "      <td>443.780811</td>\n",
       "      <td>432.199447</td>\n",
       "      <td>1084.732044</td>\n",
       "      <td>4.213245</td>\n",
       "      <td>4.356398</td>\n",
       "      <td>5.463955</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>1.118314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>501.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>851.750000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>874.750000</td>\n",
       "      <td>1207.500000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1226.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1247.000000</td>\n",
       "      <td>2146.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1615.250000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>947.250000</td>\n",
       "      <td>1633.000000</td>\n",
       "      <td>3064.500000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>3998.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean     1238.518500     0.4950     1.522250     0.509500     4.309500   \n",
       "std       439.418206     0.5001     0.816004     0.500035     4.341444   \n",
       "min       501.000000     0.0000     0.500000     0.000000     0.000000   \n",
       "25%       851.750000     0.0000     0.700000     0.000000     1.000000   \n",
       "50%      1226.000000     0.0000     1.500000     1.000000     3.000000   \n",
       "75%      1615.250000     1.0000     2.200000     1.000000     7.000000   \n",
       "max      1998.000000     1.0000     3.000000     1.000000    19.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500    32.046500     0.501750   140.249000     4.520500  ...   \n",
       "std       0.499662    18.145715     0.288416    35.399655     2.287837  ...   \n",
       "min       0.000000     2.000000     0.100000    80.000000     1.000000  ...   \n",
       "25%       0.000000    16.000000     0.200000   109.000000     3.000000  ...   \n",
       "50%       1.000000    32.000000     0.500000   141.000000     4.000000  ...   \n",
       "75%       1.000000    48.000000     0.800000   170.000000     7.000000  ...   \n",
       "max       1.000000    64.000000     1.000000   200.000000     8.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean    645.108000  1251.515500  2124.213000    12.306500     5.767000   \n",
       "std     443.780811   432.199447  1084.732044     4.213245     4.356398   \n",
       "min       0.000000   500.000000   256.000000     5.000000     0.000000   \n",
       "25%     282.750000   874.750000  1207.500000     9.000000     2.000000   \n",
       "50%     564.000000  1247.000000  2146.500000    12.000000     5.000000   \n",
       "75%     947.250000  1633.000000  3064.500000    16.000000     9.000000   \n",
       "max    1960.000000  1998.000000  3998.000000    19.000000    18.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean     11.011000     0.761500      0.503000     0.507000     1.500000  \n",
       "std       5.463955     0.426273      0.500116     0.500076     1.118314  \n",
       "min       2.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       6.000000     1.000000      0.000000     0.000000     0.750000  \n",
       "50%      11.000000     1.000000      1.000000     1.000000     1.500000  \n",
       "75%      16.000000     1.000000      1.000000     1.000000     2.250000  \n",
       "max      20.000000     1.000000      1.000000     1.000000     3.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can find that these attributes are dummy variables:blue,dual_sim,four_g,three_g,touch_screen,wifi.\n",
    "And we try to scaling values of attributes to the same level [0,1] for data normalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.226816</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.484621</td>\n",
       "      <td>0.446389</td>\n",
       "      <td>0.502075</td>\n",
       "      <td>0.502929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329137</td>\n",
       "      <td>0.501679</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>0.521893</td>\n",
       "      <td>0.320389</td>\n",
       "      <td>0.500611</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.293533</td>\n",
       "      <td>0.5001</td>\n",
       "      <td>0.326402</td>\n",
       "      <td>0.500035</td>\n",
       "      <td>0.228497</td>\n",
       "      <td>0.499662</td>\n",
       "      <td>0.292673</td>\n",
       "      <td>0.320462</td>\n",
       "      <td>0.294997</td>\n",
       "      <td>0.326834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226419</td>\n",
       "      <td>0.288518</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.300946</td>\n",
       "      <td>0.242022</td>\n",
       "      <td>0.303553</td>\n",
       "      <td>0.426273</td>\n",
       "      <td>0.500116</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>0.372771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.234302</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>0.250167</td>\n",
       "      <td>0.254276</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.484302</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287755</td>\n",
       "      <td>0.498665</td>\n",
       "      <td>0.505211</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.744322</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483291</td>\n",
       "      <td>0.756342</td>\n",
       "      <td>0.750534</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       battery_power       blue  clock_speed     dual_sim           fc  \\\n",
       "count    2000.000000  2000.0000  2000.000000  2000.000000  2000.000000   \n",
       "mean        0.492664     0.4950     0.408900     0.509500     0.226816   \n",
       "std         0.293533     0.5001     0.326402     0.500035     0.228497   \n",
       "min         0.000000     0.0000     0.000000     0.000000     0.000000   \n",
       "25%         0.234302     0.0000     0.080000     0.000000     0.052632   \n",
       "50%         0.484302     0.0000     0.400000     1.000000     0.157895   \n",
       "75%         0.744322     1.0000     0.680000     1.000000     0.368421   \n",
       "max         1.000000     1.0000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            four_g   int_memory        m_dep    mobile_wt      n_cores  ...  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000  ...   \n",
       "mean      0.521500     0.484621     0.446389     0.502075     0.502929  ...   \n",
       "std       0.499662     0.292673     0.320462     0.294997     0.326834  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.225806     0.111111     0.241667     0.285714  ...   \n",
       "50%       1.000000     0.483871     0.444444     0.508333     0.428571  ...   \n",
       "75%       1.000000     0.741935     0.777778     0.750000     0.857143  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "         px_height     px_width          ram         sc_h         sc_w  \\\n",
       "count  2000.000000  2000.000000  2000.000000  2000.000000  2000.000000   \n",
       "mean      0.329137     0.501679     0.499255     0.521893     0.320389   \n",
       "std       0.226419     0.288518     0.289880     0.300946     0.242022   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.144260     0.250167     0.254276     0.285714     0.111111   \n",
       "50%       0.287755     0.498665     0.505211     0.500000     0.277778   \n",
       "75%       0.483291     0.756342     0.750534     0.785714     0.500000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "         talk_time      three_g  touch_screen         wifi  price_range  \n",
       "count  2000.000000  2000.000000   2000.000000  2000.000000  2000.000000  \n",
       "mean      0.500611     0.761500      0.503000     0.507000     0.500000  \n",
       "std       0.303553     0.426273      0.500116     0.500076     0.372771  \n",
       "min       0.000000     0.000000      0.000000     0.000000     0.000000  \n",
       "25%       0.222222     1.000000      0.000000     0.000000     0.250000  \n",
       "50%       0.500000     1.000000      1.000000     1.000000     0.500000  \n",
       "75%       0.777778     1.000000      1.000000     1.000000     0.750000  \n",
       "max       1.000000     1.000000      1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = (data - data.min()) / (data.max() - data.min())\n",
    "data_norm.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have completed the data normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm['price_range']=data_norm['price_range'].apply(lambda x:0 if x<0.5 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 0 to represent low and use 1 to represent high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_norm.sample(frac=1.0)\n",
    "rows, cols = data.shape\n",
    "split_index_1 = int(rows * 0.1)\n",
    "split_index_2 = int(rows * 0.2)\n",
    "\n",
    "data_test:pd.DataFrame = data.iloc[0: split_index_1, :]\n",
    "data_validate:pd.DataFrame = data.iloc[split_index_1:split_index_2, :]\n",
    "data_train:pd.DataFrame = data.iloc[split_index_2: rows, :]\n",
    "    \n",
    "data_test.to_csv(\"test.csv\", index=False)\n",
    "data_validate.to_csv(\"valid.csv\",index=False)\n",
    "data_train.to_csv(\"train1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have splitted the original train set into 3 part with the ratio of 0.8 : 0.1 : 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Implemention of Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"train1.csv\")\n",
    "valid_data=pd.read_csv(\"valid.csv\")\n",
    "test_data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.950601</td>\n",
       "      <td>0.854623</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.289245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566837</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.203367</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.490982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263776</td>\n",
       "      <td>0.206275</td>\n",
       "      <td>0.307322</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.283901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.195594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.347130</td>\n",
       "      <td>0.691609</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim        fc  four_g  int_memory  \\\n",
       "0       0.738143   0.0         0.36       0.0  0.157895     0.0    0.887097   \n",
       "1       0.289245   0.0         0.24       0.0  0.368421     0.0    0.354839   \n",
       "2       0.490982   0.0         0.16       1.0  0.105263     1.0    0.887097   \n",
       "3       0.283901   1.0         0.12       0.0  0.315789     1.0    0.919355   \n",
       "4       0.885772   0.0         0.48       0.0  0.210526     1.0    0.596774   \n",
       "\n",
       "      m_dep  mobile_wt   n_cores  ...  px_height  px_width       ram  \\\n",
       "0  0.000000   0.616667  0.428571  ...   0.575000  0.950601  0.854623   \n",
       "1  0.777778   0.266667  0.571429  ...   0.566837  0.642857  0.203367   \n",
       "2  0.000000   0.900000  0.000000  ...   0.263776  0.206275  0.307322   \n",
       "3  0.777778   0.675000  0.857143  ...   0.042857  0.195594  0.000000   \n",
       "4  0.444444   0.400000  0.571429  ...   0.028061  0.347130  0.691609   \n",
       "\n",
       "       sc_h      sc_w  talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0  0.571429  0.444444   1.000000      0.0           0.0   1.0            1  \n",
       "1  0.500000  0.388889   0.388889      0.0           0.0   1.0            0  \n",
       "2  0.642857  0.666667   1.000000      1.0           0.0   1.0            0  \n",
       "3  0.928571  0.388889   0.000000      1.0           0.0   1.0            0  \n",
       "4  0.642857  0.500000   0.444444      1.0           1.0   0.0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implemention of naive bayes,we need to discretize continuous attributes into intervals and split large number into ranges.\n",
    "We don't need to consider about the dummy variables but only focus on the continuous and large variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we decide to discretize continuous attributes into intervals [0,0.5] and [0.5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data=train_data.applymap(lambda x:0 if x<0.5 else 1)\n",
    "valid_data=valid_data.applymap(lambda x:0 if x<0.5 else 1)\n",
    "test_data=test_data.applymap(lambda x:0 if x<0.5 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_bayes = time.time()\n",
    "yTrain = train_data.iloc[:,-1]\n",
    "yTrainCounts = yTrain.value_counts()\n",
    "yTrainCounts = yTrainCounts.apply(lambda x : (x + 1) / (yTrain.size + yTrainCounts.size)) #使用了拉普拉斯平滑\n",
    "retModel = {}\n",
    "for nameClass, val in yTrainCounts.items():\n",
    "    retModel[nameClass] = {'PClass': val, 'PFeature':{}}\n",
    "propNamesAll = train_data.columns[:-1]\n",
    "allPropByFeature = {}\n",
    "for nameFeature in propNamesAll:\n",
    "    allPropByFeature[nameFeature] = list(train_data[nameFeature].value_counts().index)\n",
    "#print(allPropByFeature)\n",
    "for nameClass, group in train_data.groupby(train_data.columns[-1]):\n",
    "    for nameFeature in propNamesAll:\n",
    "        eachClassPFeature = {}\n",
    "        propDatas = group[nameFeature]\n",
    "        propClassSummary = propDatas.value_counts()# 频次汇总 得到各个特征对应的概率\n",
    "        for propName in allPropByFeature[nameFeature]:\n",
    "            if not propClassSummary.get(propName):\n",
    "                propClassSummary[propName] = 0#如果有属性灭有，那么自动补0\n",
    "        Ni = len(allPropByFeature[nameFeature])\n",
    "        propClassSummary = propClassSummary.apply(lambda x : (x + 1) / (propDatas.size + Ni))#使用了拉普拉斯平滑\n",
    "        for nameFeatureProp, valP in propClassSummary.items():\n",
    "            eachClassPFeature[nameFeatureProp] = valP\n",
    "        retModel[nameClass]['PFeature'][nameFeature] = eachClassPFeature\n",
    "end_time_bayes = time.time()\n",
    "time_span_bayes = (end_time_bayes - start_time_bayes) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBySeries(data,model):\n",
    "        curMaxRate = None\n",
    "        curClassSelect = None\n",
    "        for nameClass, infoModel in model.items():\n",
    "            rate = 0\n",
    "            rate += np.log(infoModel['PClass'])\n",
    "            PFeature = infoModel['PFeature']\n",
    "            \n",
    "            for nameFeature, val in data.items():\n",
    "                propsRate = PFeature.get(nameFeature)\n",
    "                if not propsRate:\n",
    "                    continue\n",
    "                rate += np.log(propsRate.get(val, 0))#使用log加法避免很小的小数连续乘，接近零\n",
    "                #print(nameFeature, val, propsRate.get(val, 0))\n",
    "            #print(nameClass, rate)\n",
    "            if curMaxRate == None or rate > curMaxRate:\n",
    "                curMaxRate = rate\n",
    "                curClassSelect = nameClass\n",
    "            \n",
    "        return curClassSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data,model):\n",
    "        if isinstance(data, pd.Series):\n",
    "            return predictBySeries(data,model)\n",
    "        return data.apply(lambda d: predictBySeries(d,model), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 162.52 ms\n",
      "Testing time: 50.91 ms\n",
      "Naive Bayes Accuracy on Train Set:0.91375000\n",
      "Naive Bayes Accuracy on Validate Set:0.93000000\n",
      "Naive Bayes Accuracy on Test Set:0.88500000\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame({'Prediction':predict(train_data,retModel), 'Exact':train_data.iloc[:,-1]})\n",
    "acc_bayes_train=train[train['Prediction'] == train['Exact']].shape[0] / train.shape[0]\n",
    "\n",
    "valid = pd.DataFrame({'Prediction':predict(valid_data,retModel), 'Exact':valid_data.iloc[:,-1]})\n",
    "acc_bayes_valid=valid[valid['Prediction'] == valid['Exact']].shape[0] / valid.shape[0]\n",
    "\n",
    "start_time_bayes_t = time.time()\n",
    "test = pd.DataFrame({'Prediction':predict(test_data,retModel), 'Exact':test_data.iloc[:,-1]})\n",
    "acc_bayes_test=test[test['Prediction'] == test['Exact']].shape[0] / test.shape[0]\n",
    "end_time_bayes_t = time.time()\n",
    "time_span_bayes_t = (end_time_bayes_t - start_time_bayes_t) * 1000\n",
    "\n",
    "print(\"Training time: {:.2f} ms\" .format(time_span_bayes))\n",
    "print(\"Testing time: {:.2f} ms\" .format(time_span_bayes_t))\n",
    "print('Naive Bayes Accuracy on Train Set:{:.8f}'.format(acc_bayes_train))\n",
    "print('Naive Bayes Accuracy on Validate Set:{:.8f}'.format(acc_bayes_valid))\n",
    "print('Naive Bayes Accuracy on Test Set:{:.8f}'.format(acc_bayes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"train1.csv\")\n",
    "valid_data=pd.read_csv(\"valid.csv\")\n",
    "test_data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"price_range\"]\n",
    "X_train = train_data.drop(\"price_range\",axis=1)\n",
    "y_test = test_data[\"price_range\"]\n",
    "X_test = test_data.drop(\"price_range\",axis=1)\n",
    "y_valid = valid_data[\"price_range\"]\n",
    "X_valid = valid_data.drop(\"price_range\",axis=1)\n",
    "\n",
    "#转化为数组作后续处理\n",
    "X_train = np.c_[np.ones((X_train.shape[0],1)),X_train]\n",
    "y_train = y_train[:,np.newaxis]\n",
    "X_valid = np.c_[np.ones((X_valid.shape[0],1)),X_valid]\n",
    "y_valid = y_valid[:,np.newaxis]\n",
    "X_test = np.c_[np.ones((X_test.shape[0],1)),X_test]\n",
    "y_test = y_test[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(1+np.exp(-x))    #定义sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测值\n",
    "def probability(x, theta):\n",
    "    return sigmoid(x.dot(theta))\n",
    "\n",
    "#验证，计算准确率\n",
    "def accuracyLogistic(theta, x, y):\n",
    "    ref = pd.DataFrame(y,columns =['price_range'])\n",
    "    pred = pd.DataFrame(probability(x,theta),columns =['price_range'])\n",
    "    pred.loc[pred['price_range'] > 0.5] = 1\n",
    "    pred.loc[pred['price_range'] <= 0.5] = 0\n",
    "    right_count = 0\n",
    "    error_count = 0\n",
    "    for i in range(0, y.shape[0]):\n",
    "        if pred.loc[i,'price_range'] == ref.loc[i,'price_range']:\n",
    "            right_count += 1\n",
    "        else:\n",
    "            error_count += 1\n",
    "    return right_count / y.shape[0]\n",
    "\n",
    "#梯度下降，学习率为0.001，最大迭代次数为500\n",
    "def gradDesc(theta, x, y):\n",
    "    m = x.shape[0]\n",
    "    eta = 0.001\n",
    "    max_cycles = 500\n",
    "    new_valid_acc=accuracyLogistic(theta, X_valid, y_valid)\n",
    "    for i in range(max_cycles):\n",
    "        h = probability(x, theta)\n",
    "        error = h - y\n",
    "        theta = theta - eta * x.T.dot(error)\n",
    "        if i%20==0 and i>=20:\n",
    "            old_valid_acc = new_valid_acc\n",
    "            new_valid_acc = accuracyLogistic(theta, X_valid, y_valid)\n",
    "            if -0.0001<new_valid_acc-old_valid_acc<0.0001:\n",
    "                break\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 211.94 ms\n",
      "Testing time: 19.02 ms\n",
      "Logistic Regression Accuracy on Train Set:0.95687500\n",
      "Logistic Regression Accuracy on Validate Set:0.95687500\n",
      "Logistic Regression Accuracy on Test Set:0.94500000\n"
     ]
    }
   ],
   "source": [
    "theta = np.ones((X_train.shape[1],1))\n",
    "\n",
    "start_time_log = time.time()\n",
    "theta=gradDesc(theta,X_train,y_train)\n",
    "end_time_log = time.time()\n",
    "time_span_log = (end_time_log - start_time_log) * 1000\n",
    "\n",
    "acc_log_train = accuracyLogistic(theta, X_train, y_train)\n",
    "acc_log_valid = accuracyLogistic(theta,X_train,y_train)\n",
    "start_time_log_t = time.time()\n",
    "acc_log_test = accuracyLogistic(theta, X_test,y_test)\n",
    "end_time_log_t = time.time()\n",
    "time_span_log_t = (end_time_log_t - start_time_log_t) * 1000\n",
    "\n",
    "print(\"Training time: {:.2f} ms\" .format(time_span_log))\n",
    "print(\"Testing time: {:.2f} ms\" .format(time_span_log_t))\n",
    "print('Logistic Regression Accuracy on Train Set:{:.8f}'.format(acc_log_train))\n",
    "print('Logistic Regression Accuracy on Validate Set:{:.8f}'.format(acc_log_valid))\n",
    "print('Logistic Regression Accuracy on Test Set:{:.8f}'.format(acc_log_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"train1.csv\")\n",
    "valid_data=pd.read_csv(\"valid.csv\")\n",
    "test_data=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_data[\"price_range\"]\n",
    "X_train=train_data.drop(\"price_range\",axis=1)\n",
    "y_test=test_data[\"price_range\"]\n",
    "X_test=test_data.drop(\"price_range\",axis=1)\n",
    "y_valid=valid_data[\"price_range\"]\n",
    "X_valid=valid_data.drop(\"price_range\",axis=1)\n",
    "\n",
    "svm = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "start_time_svm = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "end_time_svm = time.time()\n",
    "time_span_svm = (end_time_svm - start_time_svm) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 311.92 ms\n",
      "Testing time: 8.01 ms\n",
      "SVM Accuracy on Train Set:0.98875000\n",
      "SVM Accuracy on Validate Set:0.98500000\n",
      "SVM Accuracy on Test Set:0.98500000\n"
     ]
    }
   ],
   "source": [
    "acc_svm_train=svm.score(X_train,y_train)\n",
    "\n",
    "acc_svm_valid=svm.score(X_valid,y_valid)\n",
    "\n",
    "start_time_svm_t = time.time()\n",
    "acc_svm_test=svm.score(X_test,y_test)\n",
    "end_time_svm_t=time.time()\n",
    "time_span_svm_t = (end_time_svm_t - start_time_svm_t) * 1000\n",
    "\n",
    "print(\"Training time: {:.2f} ms\" .format(time_span_svm))\n",
    "print(\"Testing time: {:.2f} ms\" .format(time_span_svm_t))\n",
    "print('SVM Accuracy on Train Set:{:.8f}'.format(acc_svm_train))\n",
    "print('SVM Accuracy on Validate Set:{:.8f}'.format(acc_svm_valid))\n",
    "print('SVM Accuracy on Test Set:{:.8f}'.format(acc_svm_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x239f0c90b20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = pd.DataFrame({\"Naive Bayes\": [acc_bayes_train*100, acc_bayes_test*100], \"Logistic\": [acc_log_train*100, acc_log_test*100], \"SVM\": [acc_svm_train*100, acc_svm_test*100]}, index = [\"train\", \"test\"])\n",
    "\n",
    "plot1 = accuracy.plot(kind='bar', figsize=(8, 6), title=\"Accuracy Comparision\", ylim=(50, 100))\n",
    "plot1.set_xlabel(\"Data Set\")\n",
    "plot1.set_ylabel(\"Accuracy (%)\")\n",
    "plot1.legend(bbox_to_anchor=(1.0, 0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在这个二分类问题中，在拟合程度上，Naive Bayes、Logistic Regression、SVM的拟合程度依次提高；在测试准确率上，Naive Bayes、Logistic Regression、SVM的测试准确率依次提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x239f445e6d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = pd.DataFrame({\"Naive Bayes\": [time_span_bayes,time_span_bayes_t], \"Logistic\": [time_span_log, time_span_log_t], \"SVM\": [time_span_svm, time_span_svm_t]}, index = [\"train\", \"test\"])\n",
    "\n",
    "plot1 = accuracy.plot(kind='bar', figsize=(8, 6), title=\"Time Comparision\", ylim=(0, 350))\n",
    "plot1.set_xlabel(\"Data Set\")\n",
    "plot1.set_ylabel(\"Time (ms)\")\n",
    "plot1.legend(bbox_to_anchor=(1.0, 0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，在训练时间上，Naive Bayes与Logistic Regression相近，而SVM的训练时间要长许多；而测试时间上，Bayes、Logistic Regression、SVM 以此下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次实现中，logistic regression采用了判断收敛并直接结束的实现方式，训练时间比常规时间偏多，而当遇到一些收敛较慢的情况时，则会比较慢。\n",
    "总体上来说，Naive Bayes、Logistic Regression、SVM 的训练时间依次增加，模型拟合程度依次增加，测试准确率依次提高。\n",
    "下对三种方法进行讨论：\n",
    "Naive Bayes：模型训练时间较短，准确率一般，同时，由于对于连续变量和大数据采用了分段归类处理，实际分类效果会受到影响。适用于哑变量较多，变量较少的情况。\n",
    "Logistic Regression：训练时间适中，准确率较高，但遇到收敛慢的情形可能会较慢。\n",
    "SVM：训练时间最长，同时准确率也最高，是目前十分优秀的二分类方法，有着极高的准确率。缺点是训练时间长。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
